<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans,en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="neverchanje">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="neverchanje">
<meta property="og:locale" content="zh-Hans,en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="neverchanje">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>neverchanje</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans,en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">neverchanje</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/27/morning_paper_lease/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/01/27/morning_paper_lease/" itemprop="url">Morning Paper - Leases, An Efficient Fault-Tolerant Mechanism for Distributed File Cache Consistency</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-27T00:00:00+08:00">
                2017-01-27
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近要研究 etcd，所以需要专门过一遍相关的资料。<br>the morning paper（我说的是 adrian colyer 的那个）给 <a href="http://web.stanford.edu/class/cs240/readings/89-leases.pdf" target="_blank" rel="noopener">这篇 paper</a> 写过 <a href="https://blog.acolyer.org/2014/10/31/leases-an-efficient-fault-tolerant-mechanism-for-distributed-file-cache-consistency/" target="_blank" rel="noopener">review</a>。</p>
<hr>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>这是一篇 1989 年的陈年老 paper。我不知道 lease 这种策略的提出具体是在什么时候，不过看这篇论文的表述，应该是在论文发表前蛮早就提出来了。</p>
<p>lease 的原理很简单。一般 client 想要操作某个共享资源，就要申请一次所有权，操作完之后释放所有权。每次使用资源，都要申请一次，如果频繁使用，就要频繁申请。申请所有权的过程可能比较复杂，比如需要通过 ACL，比如要写 wal 等等，这时候的开销就让人头疼了。这就有了 lease。</p>
<blockquote>
<p>A lease is a contract that gives its holder specified rights over property for a limited period of time.</p>
</blockquote>
<p>lease 就是“租”资源，国内叫租约，资源使用完之后不释放，一直到租期超期才自动释放。这样只要在租期内，即使频繁获取资源，实际也只会执行一次申请操作。</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>这篇论文其实给 lease 做了一个理论评估，看看理论上 client 要如何设置租期，才会得到更高的 benefit。</p>
<blockquote>
<p>Given a read rate of R, write rate of W, and a file shared between S caches then the lease benefit factor B is given by B = 2R/SW. And you’ll be getting benefit from a leasing scheme so long as the amount of time a client holds a lease (without renewing) is &gt; 1/(R(B-1)).</p>
</blockquote>
<p>坦白说，我尝试去看计算的过程，不过没理解。colyer 帮我们做了一个总结。未来这个结论可以帮助我们设置 lease term。</p>
<h2 id="Applicability-to-Distributed-System"><a href="#Applicability-to-Distributed-System" class="headerlink" title="Applicability to Distributed System"></a>Applicability to Distributed System</h2><p>lease 可以用来缓解分布式系统里的 false sharing。我们知道 cpu 的 false sharing 指的是两个 clients 同时操作一条 cacheline 的数据。分布式系统的 false sharing 指的是：</p>
<blockquote>
<p>Short lease terms also minimize the overhead due to false sharing – where a client wants to write to a file that is covered by a lease held by another client, when in fact that client is no longer using it.</p>
</blockquote>
<p>上面这段摘自 colyer。</p>
<p>Fault Tolerance<br>其实这是整篇论文里我最在意的点，但是这段的篇幅却很少。</p>
<p>假设 server 只有一台机器，由于时钟不同步，client 和 server 可能在不同的时刻认为 lease 过期。不管是 server 过早地认为 lease 过期，还是 client 过晚地判定 lease 过期，都会造成 client 申请资源失败，这是一种 inconsistency。所以我们需要有一个 epsilon（简称 e，e&gt;0），申请 lease 的时间是 ts，server 的过期时间为 ts + lease + e，client 的过期时间为 ts + lease - e。</p>
<p>上面是 server 只有一台的情况，如果 server 有多台做 quorum（甚至要考虑跨机房），问题就会大了。论文里没考虑到这点。</p>
<p>除此之外，我们还需要考虑 Redis RedLock 中关于进程 hang 住导致锁分配不一致的问题，也是和 lease 有关。</p>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>未来我要看一下 colyer 推荐的 <a href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf" target="_blank" rel="noopener">Scaling memcache at Facebook</a> 这篇 paper。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/24/redis_others/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/01/24/redis_others/" itemprop="url">Redis Internals, Other Features</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-24T00:00:00+08:00">
                2017-01-24
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这篇文章主要是我自己做个整理笔记的，有点滥竽充数的意思，相关内容的详细描述很多都能 google 到更好的。</p>
<h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>HyperLogLog 是用来解决 distinct elements problem 的一种算法，比如计算访问某个 URL 的不同 IP 数，从而计算 DAU。<br>坦白说我曾经花了整整一天时间调研 HyperLogLog，不过还是没搞懂这套算法，最终放弃。</p>
<p><strong>参考</strong>：</p>
<ul>
<li><a href="http://blog.codinglabs.org/tag.html#%E5%9F%BA%E6%95%B0%E4%BC%B0%E8%AE%A1" target="_blank" rel="noopener">博主 CodingLabs 关于基数估计算法的专题博文</a></li>
<li><a href="http://antirez.com/news/75" target="_blank" rel="noopener">antirez 关于 redis HyperLogLog 的介绍博文</a></li>
</ul>
<h2 id="Pub-Sub"><a href="#Pub-Sub" class="headerlink" title="Pub/Sub"></a>Pub/Sub</h2><p>实现消息队列的订阅发布功能。</p>
<p>我们可以认为，redis server 在内存中维护了如下的数据结构：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">map</span>&lt;robj*, <span class="built_in">list</span>&lt;client*&gt;&gt; pubsub_channels; <span class="comment">// &lt;channel&gt; -&gt; &lt;list of clients&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>PUBLISH</strong><br>每发布一条消息，立刻对所有订阅该消息的 clients 发送该条消息。</p>
<p><strong>SUBSCRIBE</strong><br>订阅其实就是在 pubsub_channels[channel] 里加入当前的 client。等价于：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pubsub_channels[channel].push_back(client);</span><br></pre></td></tr></table></figure>
<p>订阅发布功能可以用在 sentinel 上，一旦 redis 实例出现了偏差，sentinel 就通知订阅的客户端。</p>
<h2 id="RedLock"><a href="#RedLock" class="headerlink" title="RedLock"></a>RedLock</h2><p>RedLock 其实不是一个 feature，它只是利用 redis 来做分布式锁的一个算法，具体的实现交给社区，目前看应该没有一个经过线上考验的官方实现，再加上这个 proposal 也算是半个伪需求，哪怕 redis 在自己之上实现一个 raft，我也很难不去考虑更 full-featured 的 zk 和 etcd。</p>
<p><a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">Distributed locks with Redis</a>： 关于 Redlock 的官方文档。假设 5 Redis 实例，申请锁就向每个实例依次发起请求，其中有一个请求超时就不断重试，释放锁就向每个实例请求释放。在锁之上做 lease，如果申请锁的过程耗时超过 lease 时长，则当做申请锁失败。最终如果过半实例判决同意锁申请，就算申请成功。<br>这个算法可吐槽的地方太多，我都不知道从哪里吐槽起。我个人对 antirez 是十分尊敬的，我从他身上学到了很多做工程和做开源的经验。但是我们应该能意识到，分布式锁算法本质涉及到一致性问题，而 RedLock 其实只负责了 log replication，failover 阶段也只负责了 recovery（把锁的获取操作日志利用 aof 持久化，后续可以从日志里 recover 起来），而没有负责新节点的 catch up。不考虑 catch up，这个算法就是不完整的，一个不完整的算法是没有对错之分的。catch up 需要一个分布式递增计数器，这个算法里没有提供（id 用的是 UUID）。<br>RedLock 算法强制使用 lease（antirez 把这叫 auto-release，即锁经过一段时间就会自动释放），我们假设是 short lease，虽然在一个 lease 内的操作正确性不那么好保证，但是经过 lease 后锁会失效，一定程度上可以减轻错误的代价。不过这也说明 RedLock 作为一个分布式锁算法，本质是在用 correctness 做 tradeoff，增加了 performance。所以正如下面的博文作者 Martin 提到的，与其花 5 台 redis 做 RedLock，还不如直接用 2 台 redis 做主从切换。</p>
<p><a href="http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html" target="_blank" rel="noopener">How to do distributed locking, Martin Kleppmann</a>：这篇博文干货太多了。背景是这样的，antirez 提出 RedLock 算法，希望社区有人可以评估一下，然后博主有理有据地否定了这个算法，当然这是个一黑顶十粉的事情。<br>Martin 提出一个蛮有意思的问题，假设 client 申请到锁之后，lease 还没超时，于是 client 尝试对某个 shared resource 做写操作，如果此时写操作的过程中进程出现很长的停滞（比如 STW GC），此时 lease 超时，理论上写操作应该失效，然而我们没有任何的机制可以让写操作失效。如果不让它失效，旧的写操作会覆盖新的写操作。</p>
<p><img src="http://og0xhkmh3.bkt.clouddn.com/redislock_unsafe-lock.png" alt="redlock gc block"><br>这个问题不是 RedLock 的锅，理论上任何使用 lease 策略的分布式锁都会有这个问题，比较麻烦。</p>
<p><a href="http://antirez.com/news/101" target="_blank" rel="noopener">Is Redlock safe?</a>：这就是 antirez 应对 Martin 的批判写的博文。<br>坦白说我对分布式系统的时钟相关的知识储备比较薄弱。</p>
<p>参考：</p>
<p><a href="http://weizijun.cn/2016/03/17/%E8%81%8A%E4%B8%80%E8%81%8A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E8%AE%BE%E8%AE%A1/" target="_blank" rel="noopener">聊一聊分布式锁的设计</a> 这篇文章可能有一定误导性，我个人不是很喜欢，不过可以作为参考。</p>
<h2 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h2><p>redis 的事务 官方文档。我经常忘了事务怎么写，所以在这里记一下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">&gt; INCR foo</span><br><span class="line">QUEUED</span><br><span class="line">&gt; INCR bar</span><br><span class="line">QUEUED</span><br><span class="line">&gt; EXEC</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br></pre></td></tr></table></figure>
<p>客户端发送 MULTI，输入一系列指令，输入 EXEC 执行，返回结果。一开始我以为 EXEC 之前的操作都可以交给 client 去做，等到 EXEC 再将事务所有命令发送给 server，减小 server 的负担。然而 redis 在这里的每一个命令都会与 server 交互，像 INCR foo，INCR bar 这些命令，都会经过 redis 的正确性检查，只有命令正确才会返回 QUEUED。<br>所以说明 redis 协议必须是有状态的。<br>这可能也是为了减轻 client 的负担，避免不同语言 clients 的实现参差不齐。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; fuck</span><br><span class="line">(error) ERR unknown command &apos;fuck&apos;</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br></pre></td></tr></table></figure>
<h2 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h2><p>redis 应该只支持 plain text 的 authentication。相关原因可以参考官方文档 <a href="https://redis.io/topics/security" target="_blank" rel="noopener">Redis Security</a>。<br>唯一一个考虑到安全性的地方，是 <code>server.c:time_independent_strcmp</code>，这里用来比较密码。如果用 strcmp，我们可以通过执行时间的长短，猜出密码。用 <code>time_independent_strcmp</code> 的目的是想让不管什么长度的密码，比较的耗时都一样，攻击者就猜不出密码。</p>
<p>我来说下用 strcmp 的时候怎么猜密码：攻击者猜一个密码，假设 n 个字符猜对了前 k 个，我们尝试猜第 k+1 个，如果猜对了，比较耗时应该更长。猜错了，耗时不变。这样我们就可以暴力把密码猜出来。</p>
<p><code>time_independent_strcmp</code> 在实现上确实避免了这种攻击方式，不过显然的安全性还不够。可以参考 mongodb 在 SASL 框架之上加了 SCRAM-SHA1，还支持 TLS。当然，这些官方肯定比我们更清楚。</p>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>之后我们有必要调研一下 <a href="https://aphyr.com/posts/283-jepsen-redis" target="_blank" rel="noopener">Jepsen: Redis</a> 这篇博文的内容。<br>未来我要看一下 etcd 的 lease 实现，RedLock 的问题在 etcd 中一定也会有。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/23/jmiss_sentinel/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/01/23/jmiss_sentinel/" itemprop="url">从 JIMDB sentinel 到 Health Check</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-23T00:00:00+08:00">
                2017-01-23
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Intro-to-JIMDB"><a href="#Intro-to-JIMDB" class="headerlink" title="Intro to JIMDB"></a>Intro to JIMDB</h2><p>最近看到京东基础平台团队有人把设计放到微信公众号上，我就想以一个无知者的角度，评判一下 JIMDB sentinel 的设计。读者在读这篇文章之前，可以先看看公众号里的内容。</p>
<p>JIMDB 是一个基于 docker 的 redis 集群管理平台，功能相对是比较丰富的，比 redis cluster 要多了一些功能。比如 redis failover 时 docker 资源分配，监控数据采集。公开的介绍文章总是喜欢强调：京东拿它来管理数十万 Redis 实例 —— 其实明白人都知道这不代表技术就一定多牛逼，多稳定 —— 当然它肯定有其优秀之处的。</p>
<h2 id="Sentinel"><a href="#Sentinel" class="headerlink" title="Sentinel"></a>Sentinel</h2><p>我们看看他们怎么描述这个架构的：</p>
<blockquote>
<p>多个探测实例同时对同一个JIMDB实例进行探测，只要一个探测实例检测到服务端实例是存活的，那么该实例就认为是存活状态，当没有人反馈其为存活状态，且超过半数的探测实例认为该实例死亡时，则通知故障恢复程序进行主从切换…</p>
</blockquote>
<p>这个探测实例指的就是 sentinel，熟悉 redis 的应该知道，在定位上，它和 redis 2.8 即已引入的 sentinel 没有半点区别。我并不清楚他们自己重写一个的理由，不过如果把 sentinel 的实现从纯 C 转为 golang，那需要的代码行数应该会少一些。我觉得 sentinel 是适合用 golang 来做的。当我们把一个分布式系统的逻辑从复杂的代码里解放出来，我们就更容易编写正确的代码，加之它对性能也不那么敏感，用 C 写真是太费力了。</p>
<p>我们可以猜到上述提到的 “故障恢复程序” 就是指的 failover 模块。redis sentinel 里 failover 模块和 sentinel 是紧耦合的，我认为应该解耦出来。将 failover 解耦出来的设计应该是这样的：我们不需要考虑 master 底下有哪些 slaves，我们把 master 和 slave 都统一以 “节点” 为概念管理，一旦 sentinel 检测到某个节点出错，就提醒 failover 模块，由 failover 模块决定接下来的步骤，如果该节点是 master，就选一个 slave 接替。failover 模块也需要负责向资源模块（resource manager）申请新资源。</p>
<p>我认为 redis sentinel 并不是一个优秀的设计（当然我们必须承认 antirez 在分布式系统的经验，也必须承认 redis 在单机下是非常优秀的产品）。JIMDB 团队一开始有考虑过用 zookeeper 来代替 sentinel，然而他们认为 zookeeper 做健康监控太重，zk 很可能无法撑住如此多的 redis 实例。不过 zookeeper 可以用来做 sentinel 之间的 leader 选举。</p>
<blockquote>
<p>在故障检测和故障切换的方案中，比较容易想到的方案就是引入zookeeper，通过zookeeper的临时节点探测不存活的服务，但是由于需要修改服务端代码、不方便跨机房部署、watch数目和连接数过多有性能问题等原因最终没有被采用…</p>
</blockquote>
<p>我们可以参考 kubernetes 的设计，理论上一台物理机应该可以有十几台 redis 实例（这里我们假设每个 redis 实例占用一个 cpu core，当然部署上百台也是可以的）。我们可以让 sentinel 负责对一台物理机发 ping，物理机上开一个 agent 进程，负责监控机器上所有 redis 实例的健康状态，比如进程是否 hang 住。如果 agent 无法响应 pong，那说明物理机上一定是多数 redis 实例都停滞了（可能是网络问题，cpu 调度问题，io 调度问题）；如果一个 redis 实例挂了（比如某些 fatal error），agent 发现后就能返回错误状态给 sentinel。这样 sentinel 只需要维护 (number of machines = number of redis / 1x) 条长连接，相对会轻松很多，这时候就可以用 zk 做健康监控了。</p>
<p><img src="http://og0xhkmh3.bkt.clouddn.com/redis/sentinel_with_pod.PNG" alt="sentinel with pod"></p>
<p>我们知道 sentinel 检测到 SDOWN 的时候会询问其他 sentinels，如果过半的 sentinels 也认为 SDOWN，则结果为 ODOWN，即客观下线。其实这带来一个 availability 的问题，假如 5 个 sentinel 集群统一管理上百（比较少了）个 redis 实例，假设放在同一机房，3 个 sentinel 出现网络分区，它们就会误报错误，认为所有的 redis 实例全部 ODOWN。按照原有逻辑，它们会 failover 所有的节点。sentinel 本质上既不是 cp 系统，也不是 ap 系统（观点来自 Jepson）。一个非高可用方案去做集群健康检查，我认为不是那么靠谱，这是任何集中式健康检查系统的通病。整个集群的可用性依赖于 sentinel 的可用性，这很可怕。说实话，心跳检测并没有那么的 critical，因为心跳服务不可用导致所有 redis 不可用，我认为是不可容忍的。</p>
<p>就上面关于 sentinel 误报错误的问题，我们可以加上一个逻辑：如果过多的 redis 实例出现 ODOWN，就不做 failover。当然这种方案靠不靠谱，读者可以自己考虑。</p>
<p>一个 sentinel 发现 master 失效后，它收集投票，过半则 ODOWN。这步没有问题，但在确认 ODOWN 之后，它需要将 ODOWN 日志分发给其他 sentinels，这步会带来一致性问题。我们可以用 zk 来做这次日志分发。</p>
<p>我认为 sentinel 需要一个严格正确的一致性方案，如果不行，那就干脆牺牲一致性。Jepson 尝试用 TLA 证明 sentinel 的正确性，然而他认为整个方案过于复杂，难以证明（不过 Jepson 在博文里一些观点有点问题）。</p>
<h2 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h2><p>上面关于 sentinel 因为 CP 机制而失去高可用的结论，其实存在误导，读者有兴趣可以接着往下看。</p>
<h1 id="Health-Check"><a href="#Health-Check" class="headerlink" title="Health Check"></a>Health Check</h1><h2 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h2><p>关于 zk 连接过多会带来性能问题，准确说是直接利用 zk 实现 health check 的方法对性能要求比较高。要实现 health check，我们可以让服务注册一个 ttl 节点到 zk，每隔一个心跳周期内，节点必须更新 ttl，否则节点超期，服务失效。</p>
<p>我们可以想到，每次心跳都要写日志到磁盘，更新一次 ttl，然后 commit 到 quorum。我暂时没有具体看过 zk/etcd 的 lease 实现，不过我认为写磁盘是不可避免的。所以简单地说，这种方案是不可容忍的。</p>
<p>当然读者可以辩解，现在机器性能越来越高，zk 还是能够支撑一定规模的集群的。</p>
<p>然而谁会不计成本的，专门用一个 zk 集群来做心跳呢。</p>
<h2 id="SWIM"><a href="#SWIM" class="headerlink" title="SWIM"></a>SWIM</h2><p>上面我们说到集中式健康检查存在问题，而事实上，<a href="http://www.cs.cornell.edu/~asdas/research/dsn02-swim.pdf" target="_blank" rel="noopener">SWIM</a> 很早就提出了使用 Gossip 协议做非集中式，点对点的心跳检测，极大程度降低了误报率，提高 failure dection 的可靠性。开源实现对应 <a href="https://github.com/hashicorp/serf" target="_blank" rel="noopener">hashicorp/serf</a>。这是 AP 模型，虽然我不知道是否有企业采用，并且使用 Gossip 似乎会带来运维部署，日志追踪上的问题，但整个方案依然非常吸引我。</p>
<h2 id="Baidu-Galaxy"><a href="#Baidu-Galaxy" class="headerlink" title="Baidu/Galaxy"></a>Baidu/Galaxy</h2><p>在 COISF 上，baidu galaxy 团队分享过他们在服务探活方面的<a href="http://www.10tiao.com/html/421/201702/2247484511/1.html" target="_blank" rel="noopener">经验</a>。与很多方案一样，其实本质上 galaxy 也是用类似 zk 的强一致集群（<a href="https://github.com/baidu/ins" target="_blank" rel="noopener">iNexus</a>）管理元数据的，其中就包括服务探活。</p>
<p>但与我们上面提到 zk 的服务探活方案不同，在 galaxy 上，真正的服务探活工作是 AppMaster 做的。一个集群可以有多个 AppMaster groups，在探活的过程中有任何元数据的交换，可以使用 ins 服务。我们知道，一般来讲只会在某一服务发生 failure 的时候才会需要 ins，而 failure 的概率并不高，这就缓解了 ins 的压力。</p>
<p>继续上面的讨论：AppMaster 真的会因为 ins 不满足 CAP 的 A，而不够高可用吗？</p>
<p>其实这么说是有失偏颇的。虽然 ins 本身不满足 A，但是我认为心跳服务应该是足够高可用的（单纯纸上谈兵的说）。心跳服务失效的概率是 服务失效概率，AppMaster 失效概率，ins 节点失效概率的乘积关系（具体不会算），这个概率具体能不能到高可用（99.999%），需要靠实践经验判断。galaxy 团队回答了我这个问题，他们说 galaxy 使用该方案至今还是比较稳定的。</p>
<p>另一方面，ins 的可用性可以通过错开机架，跨机房部署来获得一定的提升。如果可用性达到高可用的程度，理论上我们应该可以不需要在意这个问题。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>讲真的京东这篇文章关于 Sentinel 的介绍非常粗略，很多关键点都没有讲到，我个人比较反感这样的写作态度，当然或许他们有难言之隐呢，对吧。</p>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>[ ] 我们之后看看 Codis 如何应对上述问题。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/15/morning_paper_use_of_formal_methods_at_aws/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/01/15/morning_paper_use_of_formal_methods_at_aws/" itemprop="url">Morning Paper - Use of Formal Methods at Amazon Web Services</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-15T00:00:00+08:00">
                2017-01-15
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>我个人非常喜欢这篇文章。写好一篇文章其实不容易，首先要梳理好文章脉络，然后以读者的角度数易其稿，方能发表。不像我写博客，想到哪写到哪。</p>
<p>这是一篇 <a href="http://glat.info/pdf/formal-methods-amazon-2014-11.pdf" target="_blank" rel="noopener">technical report</a>。文章所讲述的是 AWS 将形式化方法广泛应用在工程上的经验和心得。AWS 从 2011 年开始使用 TLA+ 来证明分布式系统设计的正确性。TLA+ 是 Leslie Lamport 开发的（膜）一种专门用于形式化并发系统或分布式系统的语言。最初我是看到 Raft 的 Specification 是用 TLA+ 形式化描述的，才了解到了这个工具，然后读到了这篇文章。经过 TLA+ 描述之后，我们可以使用 TLC 进行 model checking，验证设计的正确性。</p>
<p>通常我们设计分布式系统要考虑各种 corner cases，然而时不时还是会有意想不到的 bug 出现。随着业务量的剧增，这在 AWS 是不可接受的。AWS 一开始的开发流程基于传统的方法，讲起来已经比较完善了。Design Review，Code Review，Static Code Analysis，Stress Testing，Fault-injection Testing，在国内如果流程这么完善已经非常优秀的团队了吧。然而还是不够，多种小概率事件的组合发生，还是会引发深埋逻辑里的问题。更多地，像 TLA+ 这样的方法，能够让研发人员对系统更 Confident，这非常重要。</p>
<p>此前我们描述一个设计的时候，会专门编写复杂的文档，然而当系统经过长时间的演化，每一个新的改动可能都需要我们考虑其对系统正确性的影响。这很麻烦。麻烦归麻烦，做还是要做的。为了减少工作量，我们可以只对核心关键的组件进行正确性证明，当然这就牺牲了一定的严谨性，牺牲一定的 confidence。还有一种方法是手写状态机，文章中提到 S3 团队画出了一个复杂的状态机，然后跑 Java 来暴力做模型检验。我挺佩服这种举措的，当然用 TLA+ 能够更好地解决这个问题。</p>
<p>文章里讲到他们对比过 Alloy 和 TLA+，最终他们发现 TLA+ 的表达能力更强，这是他们最早将其工程化的尝试。最早尝到甜头的这个工程师，试图将经验分享给其他人。然而大家一听到这么学术化的东西，立刻就敬而远之，无人跟进。</p>
<p>形式化方法这个名词听起来就难以让大众所接受，而 TLA+，一看就是实验室里跳出来的，没办法在工业界应用的样子。</p>
<p>后来，在 DynamoDB 开发的时候，他们 Mock 了各种网络层的故障可能，用来做 fault-injection。另一方面他们做了一些 informal proofs，保证设计的正确性，然而还是不够，还是不能保证设计没问题。设计有问题，代码就几乎不可能没问题。最终当然，DynamoDB 使用了 TLA+，效率迅速提高，甚至 Dynamo 的作者提到了，早知道有 TLA+，那他一定一开始就用了。</p>
<p>即使这个技术再好，如果宣传上不够接地气，还是难以推广。作者希望这个技术能够在公司范围内普及，所以他们在 slides 的一开始，没有提到 TLA+，没有提到形式化，没有提到验证（verification），很取巧地，他们把标题定为 Debugging Designs。这是个很好的经验，任何领域的技术人都需要这种技术推广的技巧。反观国内很多技术分享，要么没有考虑听众感受，没有重点；亦或者直接分享水货，大家都能听懂，但并没有什么意思。</p>
<p>后来 S3 团队也采纳了，并且他们发现 <a href="http://research.microsoft.com/en-us/um/people/lamport/tla/pluscal.html" target="_blank" rel="noopener">PlusCal</a> 更好用。PlusCal 可以用一种更像 C 的方式做设计，不像 TLA+ 那么数学化。PlusCal 可以被转换成 TLA+，然后用 TLC 做模型检验。</p>
<p><img src="http://og0xhkmh3.bkt.clouddn.com/TLA_application_at_aws.PNG" alt="TLA+ at aws"></p>
<p>可以看到 TLA+ 帮助 AWS 解决了许多设计缺陷。除此之外它还有一些 side affects：</p>
<ul>
<li><p>把系统设计形式化，可以让系统研发者更理解自己的设计。</p>
</li>
<li><p>梳理了整个流程之后，我们可以更好地在流程之中做 Assertion。原来我们也会经常写 assertions（感觉国内团队是不是做的少一点），但是会遇到一个问题是我们并不是总能 assert 到关键的点。有了形式化的方法，我们可以按照 spec，让代码不会违反这些保证系统正确性的 invariants。</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/08/sofa_pbrpc_http/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/01/08/sofa_pbrpc_http/" itemprop="url">baidu sofa-pbrpc 源码阅读：HTTP</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-08T00:00:00+08:00">
                2017-01-08
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>原生支持 http 是 sofa 的一个重要需求。官方文档对 HTTP 支持有较完善的描述。</p>
<h2 id="简单运行"><a href="#简单运行" class="headerlink" title="简单运行"></a>简单运行</h2><p>在了解 HTTP 实现之前，我们可以先了解一下 sofa 的 server 端是如何运行起来的，这里参考源码中的 sample/echo。</p>
<p><img src="http://og0xhkmh3.bkt.clouddn.com/sofa_server_startup.png" alt="sofa-server-startup"></p>
<p>启动 RpcServer 之后，我们即可以通过 HTTP 发送请求。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 使用 httpie 发送 request</span><br><span class="line">http -j -v http://localhost:12321/sofa.pbrpc.test.EchoServer.Echo message=&quot;Hello, world&quot;</span><br><span class="line"># request 内容</span><br><span class="line">POST /sofa.pbrpc.test.EchoServer.Echo HTTP/1.1</span><br><span class="line">Accept: application/json</span><br><span class="line">Accept-Encoding: gzip, deflate, compress</span><br><span class="line">Content-Length: 27</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Host: localhost:12321</span><br><span class="line">User-Agent: HTTPie/0.8.0</span><br><span class="line">&#123;</span><br><span class="line">    &quot;message&quot;: &quot;Hello, world&quot;</span><br><span class="line">&#125;</span><br><span class="line"># response 内容</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Access-Control-Allow-Origin: *</span><br><span class="line">Content-Length: 40</span><br><span class="line">Content-Type: application/json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;message&quot;: &quot;echo message: Hello, world&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="HTTP-Or-Binary"><a href="#HTTP-Or-Binary" class="headerlink" title="HTTP Or Binary"></a>HTTP Or Binary</h2><p>仔细想想会觉得莫名其妙，上面的流程图里，我们没有在任何地方指定使用 HTTP 作为请求的方法，然而 sofa 却可以判断我们使用 HTTP，并且返回 HTTP response。这是否意味着消息传输只能用 HTTP？</p>
<p>其实并非如此，sofa 还支持 Binary Message 的消息传输方式，具体格式可以参考官方文档。Binary Request 与 HTTP Request 类似，它也具有 header 部分和 body 部分。Binary Message 相比 HTTP message 最大的不同在于，整个信息使用的是尽可能紧凑高效的序列化二进制，而非简单可读的文本。</p>
<p>Binary Request 的 header 部分前四字节为 magic string，而 HTTP Request 的 header 部分前四字节为 method 字段（sofa 只支持 POST 和 GET）。所以我们可以通过 request message 的前四个字节，判断请求是 Binary Request 还是 HTTP Request。具体流程如下：</p>
<p>服务端接收请求，通过确认 magic string（<code>HTTPRpcRequestParser::CheckMagicString</code>），可以知道该请求是一个 HttpRpcRequest，随后即进行处理（<code>HTTPRpcRequest::ProcessRequest</code>）。</p>
<h2 id="Servlet：用-sofa-做-web-服务器"><a href="#Servlet：用-sofa-做-web-服务器" class="headerlink" title="Servlet：用 sofa 做 web 服务器"></a>Servlet：用 sofa 做 web 服务器</h2><p>通过上图我们可以看到，除了利用 protobuf 做 RPC 以外，sofa 还能直接拿来写 web 服务器。我们可以在某个 URL 子目录（path）下注册回调函数（<code>RpcServerImpl::RegisterWebServlet</code>），这样就可以在访问某个 URL 的时候执行对应操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">http http://localhost:12321/hello</span><br><span class="line"># response 内容</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Access-Control-Allow-Origin: *</span><br><span class="line">Content-Length: 41</span><br><span class="line">Content-Type: text/html; charset=UTF-8</span><br><span class="line">&lt;h1&gt;Hello from sofa-pbrpc web server&lt;/h1&gt;</span><br></pre></td></tr></table></figure>
<p>Servlet 就是这里的回调函数。Server 接收 HTTPRequest，经过 Servlet 的处理，返回 HTTPResponse：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> ExtClosure&lt;<span class="keyword">bool</span>(<span class="keyword">const</span> HTTPRequest&amp;, HTTPResponse&amp;)&gt;* Servlet;</span><br></pre></td></tr></table></figure>
<p>上面的例子里，我们的 Servlet 接收到任何 request，都会返回 <code>&lt;h1&gt;Hello from sofa-pbrpc web server&lt;/h1&gt;</code>。</p>
<p>其实非要拿 sofa 做 web 服务器就太牵强了，我们更应该用其他更广泛使用的开源 web 服务器。sofa 实现 servlet 的一个重要理由其实是可以<a href="https://github.com/baidu/sofa-pbrpc/wiki/%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8#web%E7%9B%91%E6%8E%A7" target="_blank" rel="noopener">做监控页面（建议读者自己尝试一下）</a>。每个内置的监控页面都注册了对应的 Servlet。本质上用户也可以针对自己的使用，注册相应的 web 监控页面。</p>
<p>能想出这个功能也是很可爱。因为正常情况下都是返回一个 JSON，谁会自己用 C++ 写个 html 出来。不过当然这也启发我们联想，可能我们有一个特殊的 RPC server，它的监控信息需要用前端渲染，这时候用 C++ 写 html 是绝对不行的。我们可以嵌入 JS，可以加 css。</p>
<h2 id="请求使用-JSON-还是序列化的-protobuf"><a href="#请求使用-JSON-还是序列化的-protobuf" class="headerlink" title="请求使用 JSON 还是序列化的 protobuf"></a>请求使用 JSON 还是序列化的 protobuf</h2><p>HTTP 的 request body 默认以 JSON 传输。还是用 <a href="https://github.com/baidu/sofa-pbrpc/tree/master/sample/echo" target="_blank" rel="noopener">sample/echo</a> 中的 EchoService 作为例子。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 使用 POST</span><br><span class="line">curl -d &apos;&#123;&quot;message&quot;:&quot;Hello, world!&quot;&#125;&apos; http://localhost:12321/sofa.pbrpc.test.EchoServer.Echo</span><br><span class="line"># 使用 GET</span><br><span class="line">curl http://localhost:12321/sofa.pbrpc.test.EchoServer.Echo?request=%7B%22message%22%3A%22Hello%2C%20world%21%22%7D</span><br></pre></td></tr></table></figure>
<p>我们可以用 POST 和 GET 发送 JSON 请求。JSON 的格式必须符合 proto 规定的 schema。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">message EchoRequest &#123;</span><br><span class="line">    required string message = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所以我们发送的 JSON 一定要有且只有 message 这一项。Server 会对 JSON 的格式进行检验（<code>pbjson.cc:jsonobject2pb</code>）。</p>
<p><img src="http://og0xhkmh3.bkt.clouddn.com/sofa_process_http_request.png" alt="sofa process http request"></p>
<p>HTTP 同样可以直接发送序列化的 protobuf 作为 request body。但是必须使用 sofa 自定义的 POST_PB 方法。</p>
<h2 id="ServiceBoard-和-MethodBoard"><a href="#ServiceBoard-和-MethodBoard" class="headerlink" title="ServiceBoard 和 MethodBoard"></a>ServiceBoard 和 MethodBoard</h2><p>一个 RPC Server 一般注册了多个 services。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/31/sofa_pbrpc_rpc_byte_stream/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/31/sofa_pbrpc_rpc_byte_stream/" itemprop="url">baidu sofa-pbrpc 源码阅读：RpcByteStream</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-31T00:00:00+08:00">
                2016-12-31
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Boost-Asio"><a href="#Boost-Asio" class="headerlink" title="Boost.Asio"></a>Boost.Asio</h2><p>由于 sofa 建立在 asio 之上，所以读者有必要去了解一下 Boost.Asio 库。这是一个 Proactor 模型 的 io 库。</p>
<p>参考资料：</p>
<ul>
<li><a href="https://www.gitbook.com/book/mmoaay/boost-asio-cpp-network-programming-chinese/details" target="_blank" rel="noopener">Boost.Asio C++ 网络编程</a></li>
</ul>
<h2 id="RpcByteStream"><a href="#RpcByteStream" class="headerlink" title="RpcByteStream"></a>RpcByteStream</h2><p>按照 sofa 的设计，RpcByteStream 对应传输的最底层，负责 socket 通信。</p>
<p><img src="http://og0xhkmh3.bkt.clouddn.com/sofa_rpc_stream.png" alt="sofa-pbrpc stream"></p>
<p>RpcByteStream 是一个虚类，子类有 RpcServerMessageStream，RpcMessageStream。留给子类实现的接口有：</p>
<ul>
<li>on_closed</li>
<li>on_connected</li>
<li>on_read_some</li>
<li>on_write_some</li>
<li>trigger_send</li>
<li>trigger_receive</li>
</ul>
<h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><p>每个 RpcByteStream 有 128 bytes 的 buffer 用来存 error message，这个未来可能可以优化。<br>析构的时候直接调用 <code>basic_socket::close()</code> 关闭 socket，而不是用 <code>RpcByteStream::close</code>。<br><code>RpcByteStream::close(const std::string&amp; reason)</code> 用于连接出错时关闭 socket（比如异步连接超时，或是 TCP-NoDelay 设置失败）。<br>底层实现用 <code>basic_socket::shutdown(basic_socket::shutdown_both)</code>，关闭双方的 socket。close 时输出 reason。</p>
<h2 id="异步连接"><a href="#异步连接" class="headerlink" title="异步连接"></a>异步连接</h2><p>异步连接超时功能用 <code>basic_socket::async_connect</code> + <code>deadline_timer</code> 实现。async_connect 的本质其实也是用 io_service 的 post 打入 eventloop，不阻塞，立刻返回。然后用 deadline_timer 进行等待（等待同样是异步的，用 <code>boost::asio::basic_deadline_timer::async_wait</code>，超时则执行回调函数），超过 connect_timeout（<code>deadline_timer::expire_from_now</code>） 则将会直接关闭 socket（<code>RpcByteStream::on_connect_timeout</code>）。<br>sofa 只提供了异步连接方式，当然 asio 本身是提供了同步连接的。<br>唯一一个会调用 <code>RpcByteStream::async_connect</code> 的地方是 <code>RpcClientImpl::FindOrCreateStream</code>，所以异步连接针对的是 client 主动连接 server 的时候。<br>场景是这样的：在一次 RPC 调用中（<code>RpcClientImpl::CallMethod</code>），client 发送请求给 server，对每一个 server 会建立一条 stream（<code>RpcClientImpl::FindOrCreateStream</code>）。创建一条 stream 的同时，会进行一次异步连接。异步的做法能够降低 client 的 delay time，因为在等待连接建立的过程中，客户端还可以顺便构造请求报文。除了异步的方式之外，keepalive 等机制也能省去等待连接建立的开销，这是后话。</p>
<h2 id="连接建立，RpcByteStream-set-socket-connected"><a href="#连接建立，RpcByteStream-set-socket-connected" class="headerlink" title="连接建立，RpcByteStream::set_socket_connected"></a>连接建立，<code>RpcByteStream::set_socket_connected</code></h2><p>我们描述一下这个函数的使用场景：server 监听 client 发送来的 tcp 连接请求（<code>RpcListener::start_listen</code>，底层利用 <code>asio::tcp::acceptor</code>），如果 tcp 连接建立成功（<code>RpcListener::on_accept</code>），则将状态设置为 connected，即 set_socket_connected 。</p>
<h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p>我们可以看到 RpcByteStream 在建立连接的过程中，维护了一个小的状态机。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> &#123;</span><br><span class="line">    STATUS_INIT       = <span class="number">0</span>,</span><br><span class="line">    STATUS_CONNECTING = <span class="number">1</span>,</span><br><span class="line">    STATUS_CONNECTED  = <span class="number">2</span>,</span><br><span class="line">    STATUS_CLOSED     = <span class="number">3</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>RpcByteStream 把状态机的状态转移对子类完全隐藏。</p>
<p><img src="http://og0xhkmh3.bkt.clouddn.com/rpc_byte_stream_state_machine.png" alt="rpc_byte_stream_state_machine"></p>
<p>这里我们就可以完整地理清思路，Client 异步发起连接（Connecting），并在等待的过程中准备 RPC 请求报文，这中间如果发生任何的错误，包括等待时间过长，则关闭双方的 socket（Closed）。如果服务端 accept，则连接建立成功，两方都进入 Connected 状态。如果服务端在 accept 的过程中出现任何问题，则关闭双方 socket（Closed）。</p>
<h2 id="Nagle-算法"><a href="#Nagle-算法" class="headerlink" title="Nagle 算法"></a>Nagle 算法</h2><p>在连接建立的过程中（CONECTING -&gt; CONNECTED），双方都会进行 Nagle 算法的配置。<br>编译的时候可以指定 SOFA_PBRPC_TCP_NO_DELAY 选项，默认为 true，即不使用 Nagle 算法（应该是因为 RPC 场景通常重在快速响应？）。Nagle 算法即把数据包堆积在一起，堆到 MSS（ Maximum Segment Size） 再发送，提升吞吐量。<br>代码里写的挺清楚：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Disabling the Nagle algorithm would cause these affacts:</span></span><br><span class="line"><span class="comment">//   * decrease delay time (positive affact)</span></span><br><span class="line"><span class="comment">//   * decrease the qps (negative affact)</span></span><br></pre></td></tr></table></figure>
<h2 id="Keep-Alive"><a href="#Keep-Alive" class="headerlink" title="Keep-Alive"></a>Keep-Alive</h2><p>sofa-pbrpc 可以配置 keepalive 机制。在 socket 断开之后，server 并不会直接关闭 stream，而是保留，并且每个 tick 去清理一次那些长时间没有读写的 stream。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Get the last time ticks for read or write.</span></span><br><span class="line"><span class="function">int64 <span class="title">last_rw_ticks</span><span class="params">()</span> <span class="keyword">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> _last_rw_ticks;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>last_rw_ticks 记录上次读写的时间，如果 now - last_rw_ticks &gt;= keep_alive_ticks，就关闭该 stream。</p>
<p>留给子类的接口<br>我们有必要提一下 RpcByteStream 留给子类的几个接口会在哪些地方被调用，这样可以方便未来我们介绍这些子类。</p>
<ul>
<li><code>on_closed</code>：因为出错而调用 RpcByteStream::close 时用到。</li>
<li><code>on_connected</code>：只有在 client 进行异步连接的时候会用到，不过 RpcServerMessageStream 仍然实现了 on_connected（不然会编译出错）。这个设计足够，不过不够漂亮。</li>
<li><code>on_read_some</code>：RpcByteStream 提供一个 protected 的 async_read_some 方法，在异步读到数据的时候调用 on_read_some。</li>
<li><code>on_write_some</code>：与上面的 on_read_some 差不多。</li>
<li><code>trigger_send</code> 和 <code>trigger_receive</code>：这两个函数在 client 和 server 连接建立时，双方都会调用。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/19/redis_data_manipulation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/19/redis_data_manipulation/" itemprop="url">Redis Internals, Data Manipulation Operations</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-19T00:00:00+08:00">
                2016-12-19
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>两年前刚从区域赛回来，开始去读 redis 的源码，当时还是 3.0 时代，list 命令会根据不同的场景使用 adlist 和 ziplist。现在已经完全使用 quicklist 了。</p>
<p>我们可以回顾一下以前的方法：</p>
<ul>
<li>当 list 较短的时候，使用 ziplist 进行存储，在 list 较长的时候，使用 adlist 存储。具体什么时候会从 ziplist 转到 adlist？redis 提供了 list-max-ziplist-entries 选项，默认值为 512。如果 ziplist 的元素的个数超过 512，就会从 ziplist 转到 adlist。触发这个转换的时机有：PUSH，LSET 操作。（<code>&lt;=3.0</code>）</li>
<li>在删除节点的时候并不会尝试去从 adlist 转到 ziplist。（<code>&lt;=3.0</code>）</li>
</ul>
<p>显然，一旦一个 list 的生命在某时刻从 ziplist 转换成 adlist，它就再也回不到 ziplist 状态了。这对一个长期运行的程序来讲是不利的，因为可能这个 list 只是遇到了热点才变大，在它慢慢变冷之后应该回到 ziplist。</p>
<p>可以联想到，说不定会有一些人为了避免 list 永远退化为 adlist，所以选择将一个 adlist 量级的 list sharding 到多个 ziplist 量级的 lists 上，一旦一个 ziplist 满了，就按某种策略进行拆分。这个想法其实就是 quicklist 的思想。</p>
<p>在 3.2 版本的推进过程中，redis 引入了 quicklist，据说在一些场景可以提升 10x 性能（<a href="https://github.com/antirez/redis/blob/3.2/00-RELEASENOTES#L1824" target="_blank" rel="noopener">3.2 release-notes</a>）。quicklist 的思想是将 adlist 和 ziplist 结合，每个 node 是一个 ziplist，用 doubly linked list 的方式串起来。讲到这里我们基本就可以确定这是个 great idea 了。这里我们不讲具体实现， <a href="http://zhangtielei.com/posts/blog-redis-quicklist.html" target="_blank" rel="noopener">Redis内部数据结构详解(5)——quicklist，zhangtielei</a> 已经讲的足够好了。</p>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>set 操作是 unordered 的，但是保证唯一性，底层有两种实现，dict 和 intset。对这两个数据结构的简单了解可以看我的博客</p>
<h2 id="dict"><a href="#dict" class="headerlink" title="dict"></a>dict</h2><p>这里可以吐槽，dict 居然一点不改就直接被拿来做 set。redis 是这么做的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">## SADD key member</span><br><span class="line">redis&gt; SADD myset &quot;Hello&quot;</span><br><span class="line">(integer) 1</span><br><span class="line">redis&gt; SADD myset &quot;World&quot;</span><br><span class="line">(integer) 1</span><br><span class="line">redis&gt; SADD myset &quot;World&quot;</span><br><span class="line">(integer) 0</span><br><span class="line">redis&gt; SMEMBERS myset</span><br><span class="line">1) &quot;Hello&quot;</span><br><span class="line">2) &quot;World&quot;</span><br></pre></td></tr></table></figure>
<p>加一个 member 到 myset，底层对应是加一个 dictEntry 到 dict。dictEntry 是一个 key value 组合，这里的 key 是 member，value 是 NULL。这里也是不合理的，之后看看提一个 issue。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (subject-&gt;encoding == OBJ_ENCODING_HT) &#123;</span><br><span class="line">    dict *ht = subject-&gt;ptr;</span><br><span class="line">    dictEntry *de = dictAddRaw(ht,value,<span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (de) &#123;</span><br><span class="line">        dictSetKey(ht,de,sdsdup(value));</span><br><span class="line">        dictSetVal(ht,de,<span class="literal">NULL</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="intset"><a href="#intset" class="headerlink" title="intset"></a>intset</h2><p>如果集合里都是整数，就使用 intset。intset 是有序的，使用二分搜索，search 效率较高（O(logn)），所以即使 set 不要求有序性，使用 intset 也是合理的。<br>不过由于 intset 使用数组存储，集合一旦大了效率就会降低。redis 提供了 set-max-intset-entries 选项，默认值为 512，如果 intset 所的元素个数大于 512，就将底层存储从 intset 转到 dict。<br>同时，一旦往一个 intset 加入字符串类型的 member，intset 也会自动转换为 dict。</p>
<p>讲真的，这个实现还不太理想，希望有人把握这个机会写一个 quickset 出来。</p>
<h2 id="Hash-Table"><a href="#Hash-Table" class="headerlink" title="Hash Table"></a>Hash Table</h2><p>redis 的哈希表实现是这样的，如果 entries 个数小于 hash-max-ziplist-value，就使用 ziplist 来存。<br>这个实现比较奇葩，理论上这不是哈希表，构造如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">|--field1--|--value1--|--field2--|--value2--|--...--|</span><br></pre></td></tr></table></figure>
<p>这就导致此时的 HGET 操作是 O(n) 的，每次都是一个遍历去查。不过由于 ziplist 本身就对 cacheline 有优化，所以在元素数量少的情况下可能是可以容忍的。</p>
<p>entries 个数大于 <code>hash-max-ziplist-value</code> 的时候使用 dict 来存，这就不说了。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/16/redis_set/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/16/redis_set/" itemprop="url">Redis Internals, SET key value</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-16T00:00:00+08:00">
                2016-12-16
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SET-key-value"><a href="#SET-key-value" class="headerlink" title="SET key value"></a>SET key value</h2><p>虽然 value 的类型固定是 string（可以使用 TYPE key 查看，对应的是 redisObject::type），但是 value 可能有多种 encodings。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; SET key 10000</span><br><span class="line">OK</span><br><span class="line">&gt; TYPE key</span><br><span class="line">&quot;string&quot;</span><br><span class="line">&gt; STRLEN key</span><br><span class="line">(integer) 5</span><br><span class="line">################################################</span><br><span class="line">虽然我们看到的类型是 string，其实底层用 long 存储。</span><br><span class="line">这里有点欺骗用户的意思，不过想想 redis 协议应该是</span><br><span class="line">想隐藏底层存储的细节。</span><br></pre></td></tr></table></figure>
<h2 id="Encodings"><a href="#Encodings" class="headerlink" title="Encodings"></a>Encodings</h2><p>（参考 <code>object.c:tryObjectEncoding</code>）</p>
<p>熟悉序列化的肯定知道，8 字节 long 能存 20 个字符长度的整型数（LONG_MAX=9223372036854775807，算上负号就是20字符），对于大整数应该选用 long 而非 string。所以当 value 是一个整数，redis 尝试将其存储为 long。</p>
<p>这种方案显然对于小整数不友好，比如 long 存储整数 10 至少需要 8 bytes（64位机），而 string 只需要 3 bytes（使用 sds）。对于这个问题的一种优化方案是，对于小整数，我们仍然使用 sds 存储，大整数用 long 存储。redis 的优化方案更优秀。redis 将 0-10000 的整数放在公有常量池。这点在大量存储整数的场景，应该能够极大提高系统的最大负载。</p>
<h2 id="Embeded-String（new-feature-in-3-0）"><a href="#Embeded-String（new-feature-in-3-0）" class="headerlink" title="Embeded String（new feature in 3.0）"></a>Embeded String（new feature in 3.0）</h2><p>我们知道，value 的值存在 redisObject::ptr。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisObject</span> &#123;</span></span><br><span class="line">    <span class="keyword">unsigned</span> type:<span class="number">4</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> encoding:<span class="number">4</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> lru:LRU_BITS; <span class="comment">/* LRU time (relative to server.lruclock) or</span></span><br><span class="line"><span class="comment">                            * LFU data (least significant 8 bits frequency</span></span><br><span class="line"><span class="comment">                            * and most significant 16 bits decreas time). */</span></span><br><span class="line">    <span class="keyword">int</span> refcount;</span><br><span class="line">    <span class="keyword">void</span> *ptr;</span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure>
<h2 id="embeded-string-的-cacheline-优化"><a href="#embeded-string-的-cacheline-优化" class="headerlink" title="embeded string 的 cacheline 优化"></a>embeded string 的 cacheline 优化</h2><p>我们知道，sds 有一点很特别，就是它的内存布局是连续的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">|----sdshdr----|----data----|</span><br></pre></td></tr></table></figure>
<p>这意味着，每次去对 data 进行扩容，不光 data 要搬家，sdshdr 也要搬家。sdshdr 不大（有兴趣可以阅读 redis sds 的实现），所以搬家压力不大。一般的策略上，sdshdr 和 data 应该分两块内存区，这样 data 搬家的时候，sdshdr 不会搬。而 sds 设计成连续的，有各方面原因，其中一方面是可以优化 cache line，减少 cache misses。</p>
<p>我们这里讲清楚 cache line 优化的问题：在 cpu 访问 sdshdr 的时候，data 区前面的一部分也会被一起读入 cacheline。cacheline 的大小通常是 64 bytes，假如我们想把 sds 全部放到 cacheline，除去 sdshdr 的 3 bytes（sdshdr8）和 null terminator ‘\0’，还有 60 bytes 的数据会读入 cacheline。当然，如果 sds 的数据量远大于 60 bytes，那其实 cacheline 的优化就可以忽略不计。</p>
<p>现在回头看 redisObject，它的 header 有 16 bytes，64bytes 的 cacheline 除去 robj header，有 48 bytes。这个大小可以容纳 sdshdr8 的 sds，扣掉 sdshdr8 占用的 3 bytes，还有 sds 的末尾 ‘\0’，实际能够读入 cacheline 的数据量可以在 44 bytes。</p>
<p>所以 redis 在这里做了这么一个优化：如果数据长度小于等于 44 bytes（OBJ_ENCODING_EMBSTR_SIZE_LIMIT），就用 sds 的方法，将 robj header 和实际数据连在一起放置。</p>
<h2 id="公有常量池"><a href="#公有常量池" class="headerlink" title="公有常量池"></a>公有常量池</h2><p>前面说 SET key value 存储 value 时，如果 value 是一个小于 10000 的整数，则 redis 将 key 指向公有常量池里值为 value 的 robj。这样可以有很多个 keys 共享一个 value。这个思想可以放在很多地方。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sharedObjectsStruct</span> &#123;</span></span><br><span class="line">    robj *crlf, *ok, *err, *emptybulk, *czero, *cone, *cnegone, *pong, *space,</span><br><span class="line">    *colon, *nullbulk, *nullmultibulk, *queued,</span><br><span class="line">    *emptymultibulk, *wrongtypeerr, *nokeyerr, *syntaxerr, *sameobjecterr,</span><br><span class="line">    *outofrangeerr, *noscripterr, *loadingerr, *slowscripterr, *bgsaveerr,</span><br><span class="line">    *masterdownerr, *roslaveerr, *execaborterr, *noautherr, *noreplicaserr,</span><br><span class="line">    *busykeyerr, *oomerr, *plus, *messagebulk, *pmessagebulk, *subscribebulk,</span><br><span class="line">    *unsubscribebulk, *psubscribebulk, *punsubscribebulk, *del, *unlink,</span><br><span class="line">    *rpop, *lpop, *lpush, *emptyscan,</span><br><span class="line">    *select[PROTO_SHARED_SELECT_CMDS],</span><br><span class="line">    *integers[OBJ_SHARED_INTEGERS],</span><br><span class="line">    *mbulkhdr[OBJ_SHARED_BULKHDR_LEN], <span class="comment">/* "*&lt;value&gt;\r\n" */</span></span><br><span class="line">    *bulkhdr[OBJ_SHARED_BULKHDR_LEN];  <span class="comment">/* "$&lt;value&gt;\r\n" */</span></span><br><span class="line">    sds minstring, maxstring;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/14/redis_sds/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/14/redis_sds/" itemprop="url">Redis Internals, sds</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-14T00:00:00+08:00">
                2016-12-14
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>sds 可以看成是一个针对短字符串专门优化内存的字符串类，也可以被当做是一块内存区（既可以用作 buffer，也可以用作 string，熟悉 golang 的都知道这在语义上是被区分的）。<br>sds 经过两个版本的发展，我们可以依次介绍一下这两个版本：</p>
<p>1.0</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sdshdr</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> len;</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">free</span>;</span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这个版本的 sds 的特点：</p>
<ul>
<li>binary safe / 二进制安全，如果字符串中间有 ‘\0’，例如 ‘abc\0abc’，那 strlen 只会认 ‘\0’ 之前的内容。如果要修正这一点，就要将字符串长度 len 和字符串数据绑定在一起，类似 <code>std::string</code>。简单说，c string 在设计时为了放权给程序员，并没有把字符串长度跟字符串本身结合在一起，虽然几乎其他所有语言都是如此设计，但是 C/C++ 依然保持 zero-overhead。</li>
<li>为了兼容 libc 库的字符串函数（互操作性），sds 的末尾仍然以 ‘\0’ 结尾（这也算是一个牺牲）。sds 和 <code>char*</code> 等价（<code>typedef char* sds</code>），sds 指向结构体的 buf 区。这样 sds 和普通 <code>char*</code> 可以混用。</li>
<li>sds 保证一定的易用性，主要是集中在它的自动扩容上。我们知道实现字符串类一般需要三个变量，长度，空间，数据，如果原有空间不够，则需要新开辟一段更大的空间，sds 隐藏了这部分细节（所以 sds 才被叫做 dynamic string），其实扩容算法是个问题，sds 的算法比较朴实，即一旦空间不够，就扩大到原来的两倍，直到 <code>SDS_MAX_PREALLOC</code>（1mb），也就是说一个 sds 最大只能有 1mb 数据。同时除了扩容功能，sds 也给了缩容功能（<code>sdsRemoveFreeSpace</code>）。</li>
<li>易用性还包括 sds 提供的其他字符串辅助函数，都比较便利。</li>
<li><strong>性能</strong>，任何性能提升都不是平白无故的。比如 sdslen 可以做到 O(1)，而 strlen 只能做到 O(n)，这是由于 sds 保存了长度信息。sdshr 的 layout 保证了 sds 是连续的一整块内存，len, free, buf 都是连续且紧凑地放置着。这在无形中优化了 cache line，同时也减少了内存碎片。<br>看完这么多其实我还是建议大家可以去亲自看看 sds 的 README.md，可以更多地知其所以然。</li>
</ul>
<p>2.0</p>
<p>第二版的 sds 暂时缺少文档。<br>上一版的 sds 仍然有几个可以做 tradeoff 的地方：</p>
<ol>
<li><p>由于编译器自动会进行内存对齐，最终 sdshdr 的大小会是 8 的倍数（64 位机）。这在一定程度上虽然提升了性能，但是会浪费一定内存。</p>
</li>
<li><p>对短字符串不友好，对极短字符串（短到两三字符，长到20字符），其实 strlen 不会有很大开销，而 len 和 free 的 overhead 就不可忽略了（相当于 8 个字符）。这点在一些平台的 std::string 得到了缓解（<a href="http://www.cppblog.com/Solstice/archive/2012/03/17/168210.html" target="_blank" rel="noopener">C++ 工程实践(10)：再探std::string, 陈硕</a>）。</p>
</li>
</ol>
<p>问题1 的解决可以引入编译器选项 <code>__attribute__ ((__packed__))</code>，这样结构的大小和代码定义的就能完全相同，当然，这也会导致一定的性能下降。</p>
<p>问题2 比较难，redis 为不同长度的 sds 设计了不同的 header，原来的 header 是固定的，包含 8 bytes 的 len 和 free。现在的 header 能够根据不同的长度自适应地选择相应的 header。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Note: sdshdr5 is never used, we just access the flags byte directly.</span></span><br><span class="line"><span class="comment"> * However is here to document the layout of type 5 SDS strings. */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr5</span> &#123;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, and 5 msb of string length */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr8</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint8_t</span> len; <span class="comment">/* used */</span></span><br><span class="line">    <span class="keyword">uint8_t</span> alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr16</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint16_t</span> len; <span class="comment">/* used */</span></span><br><span class="line">    <span class="keyword">uint16_t</span> alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr32</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> len; <span class="comment">/* used */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr64</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint64_t</span> len; <span class="comment">/* used */</span></span><br><span class="line">    <span class="keyword">uint64_t</span> alloc; <span class="comment">/* excluding the header and null terminator */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">/* 3 lsb of type, 5 unused bits */</span></span><br><span class="line">    <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这里拿 sdshdr5 简单举个例子，原来的 header 需要 8 bytes，现在一个数据长度小于等于 <code>1&lt;&lt;5=32</code> bytes 的数据，只需要 1 byte 的 overhead。</p>
<p>sds 在引入了自适应选择 header 的策略之后，主要修改了原有的 sds 扩容和缩容的代码，其他基本保持不变。尽管如此，sds2.0 无法与 1.0 版本保证二进制兼容（因为 sds 的内存布局变了）。除此之外，API 没有发生任何变化（可以用 sdiff 确认），我认为应该可以平滑迁移。</p>
<p>每当 sds 扩容缩容的时候，都会根据新的数据长度，选择合适的 header，其实这点带来的开销不大，因为本身扩容缩容就是需要 O(n) 的。</p>
<p>除了我的博客之外，我推荐几篇还不错的文章：</p>
<ul>
<li><a href="http://zhangtielei.com/posts/blog-redis-sds.html" target="_blank" rel="noopener">zhangxiaolei: Redis内部数据结构详解(2)——sds</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-post" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/12/11/leveldb_3_version/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="neverchanje">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="neverchanje">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/12/11/leveldb_3_version/" itemprop="url">leveldb 源码解说(3)：Version 和 VersionSet</a></h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-12-11T00:00:00+08:00">
                2016-12-11
              </time>
            

            

            
          </span>

          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在阅读这篇文章之前希望读者先阅读 <a href="https://github.com/facebook/rocksdb/wiki/MANIFEST" target="_blank" rel="noopener">rocksdb wiki 关于 Version 和 VersionEdit 的介绍</a>，其实很多东西在这里已经介绍的很清楚了。</p>
<hr>
<p>Version 和 VersionSet 是 leveldb 最乱的地方之一。看的时候要保持思考保持清醒（这是个软件工程问题）。先看 <code>Version::Get</code>。</p>
<h2 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h2><p>Version 管理磁盘上所有文件的元信息（简单说就是所有 SSTables 的 metadata），比方说哪一层有哪些文件，并且为了提升效率，我们要在内存中维护这些文件的 FileMetaData，这样我们就不用每次都去读文件才能得知每个文件的 key range。这些元数据交给 Version 来维护。每次删掉一个文件，都会导致 Version 被改变，产生出一个新的 Version。能够表现当前 DB 状态的 Version，被称作 current version 。所有 Version 都被 VersionSet 用一个循环双向链表维护起来。</p>
<p>其实这就有点类似 MVCC 了。MVCC 是数据库解决并发问题的时候一个很常见的概念。利用版本号的一种实现是，并发的时候数据行有多个版本用链表串在一起，写的时候拷贝一份快照出来写，加上版本号之后就变成新版本插到链表里，每个读事务只能读比自己版本号更小的，所以本质上读的时候可以进行写操作。（参考 张帅同学在知乎的回答）</p>
<p>leveldb 也需要类似的思想。我们后面会讲到 leveldb compaction 的机制，简单说就是 leveldb 时不时的会对一些文件进行清理（可以看成是做压缩），然后把清理干净后的数据放到新的文件集合里，这样就导致同一份数据有两批文件，旧的那一批按道理应该删掉，但是如果现在有读事务在旧的那批文件上，则暂时还不能删。所以我们利用引用计数的机制，只要一个 Version 还存活着，那么它管理的所有文件都不会被删，而一旦 Version 生命周期结束，则它管理的所有文件引用计数全部减一（参考 Version::~Version），当没有一个 Version 引用这个文件，那这个文件就可以直接删了。在引用计数这一方面，还要考虑多个用户访问这个 Version 的情况。也就是说，除了文件要引用计数，Version 自己也要引用计数。</p>
<p>这里有一点要注意，memtable 不归 current version 管理。只有磁盘上的数据才归 Version 管理。不过当然，memtable 本身也有引用计数。所以在 DBImpl::Get 的时候，current，memtable，im-memtable 的引用计数都会加 1，在结束的时候减一。这样就保证读的时候 memtable 不会突然被删。</p>
<h2 id="Version-Get"><a href="#Version-Get" class="headerlink" title="Version::Get"></a>Version::Get</h2><p><code>Version::Get()</code> 查询一个 key 对应的 value，这是 leveldb 查询 key 的核心过程（划重点）。了解这步操作之前，我们首先需要知道 leveldb 的大致执行流程：首先数据会先写到 memtable，当 memtable 超过一定大小限制，数据会被持久化到 L0，为了避免在写到 L0 的同时 memtable 不可写的情况，memtable 会专门拷贝一份到 immutable memtable，顾名思义是只读的，相当于一份快照，然后利用 immutable memtable 把这份快照写到 L0。</p>
<p>执行到 <code>Version::Get</code> 这步之前（参照 <code>DBImpl::Get</code>），我们已经得知 memtable 和 immutable memtable 中没有对应 key，所以我们从 SSTable 中查（这里说的不够准确，后续再提）。查询过程显然是从上到下（level 0 -&gt; level 1 -&gt; … ）逐层遍历，这是因为 LSM tree 已经定义越新的越处于上层，所以我们一定是选择版本最新的，即含有 key 的最上层。</p>
<p>对于每一层的查询，首要的一个逻辑是定位 key 在哪一个文件，然后定位 key 在这个文件的位置，最终获得 key 的 value。</p>
<ol>
<li>在 level 0 定位 key：所以我们可以按照 file number 从大到小排序（越大的越新）然后依次遍历，每个文件都会有一个 key range（参照 FileMetaData），如果我们的 key 在该 range 里，则我们尝试在该文件里二分查找这个 key，如果 key 不在 range 里则 continue。通过 key range 过滤只是一种比较简单的优化，在 L0 的查询终究是比较慢的，所以 L0 的文件数必须要足够少（最坏情况下每个文件都要读一遍）。</li>
<li>在 level n (n&gt;0) 定位 key：在 level n &gt; 0 上，SSTables 之间的 key ranges 不会相交，我们可以利用这点进行二分找到指定文件 （参照 version_set.c:FindFile），然后在文件里进行二分找到 key（参照 TableCache::Get）。</li>
<li>如果找到的 key 对应的是 Delete record，那说明这个 key 已经被删了，返回 Status::NotFound。</li>
</ol>
<p><code>Version::Get</code> 最后会返回 key 对应的 value，key 所在的文件（GetStats）。</p>
<h2 id="VersionSet-LogAndApply"><a href="#VersionSet-LogAndApply" class="headerlink" title="VersionSet::LogAndApply"></a>VersionSet::LogAndApply</h2><p>顾名思义这个函数是用来把 VersionEdit 加到 Version 里成为新的 Version。同时这个过程也会持久化到 Manifest 上。由于涉及到磁盘 IO，不可能在每次 version 改变的时候都执行一次 LogAndApply，通常是批量做。因此，VersionEdit 中包含了一系列对 Version 的修改，包括添加了某个文件，删除了某个文件。把 VersionEdit 加到 Version 里的过程本质和 git commit 是一样的，都是旧版本经过一系列修改之后产生新版本，使用 VersionSet::Builder 执行这段过程，算法很简单，实现看起来却很复杂。</p>
<p>写 MANIFEST 的过程我们知道就是一个写日志的过程，每条 record 意味着有一组的元数据被改变， 每组改变用 VersionEdit 构造，然后 <code>VersionEdit::EncodeTo</code> 写到 record 字符串，最后用 <code>log::Writer::AddRecord</code> 写到日志里。VersionEdit 的内部构造会保证 record 的 compactness（record 里的元数据是 key value 表示，key 是元数据类型，使用 enum 标记，用 varint 存储，不同类型的元数据 value 存储方式不一样，使用 varint 和 varstring 结合存储）。</p>
<p>这里可以总结一下，有下面几个操作会执行 LogAndApply：</p>
<ol>
<li>memtable 刷到 L0 的时候（<code>DBImpl::CompactMemtable</code>），VersionEdit 会在这里记录新的 wal 编号，将 L0 的 FileMetaData 维护起来。</li>
<li>进行 compaction 的时候。VersionEdit 会记录 compaction 导致的文件增加和删除操作。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="neverchanje" />
            
              <p class="site-author-name" itemprop="name">neverchanje</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/neverchanje" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">neverchanje</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
